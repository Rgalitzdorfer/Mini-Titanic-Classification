{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Table of Contents**\n1. Data Collection\n2. Data Exploration(EDA)\n3. Data Cleaning/Feature Engineering\n4. Model Building\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-02T19:59:29.959688Z","iopub.execute_input":"2023-11-02T19:59:29.960092Z","iopub.status.idle":"2023-11-02T19:59:29.970739Z","shell.execute_reply.started":"2023-11-02T19:59:29.960061Z","shell.execute_reply":"2023-11-02T19:59:29.969404Z"}}},{"cell_type":"markdown","source":"1. **Data Collection**","metadata":{}},{"cell_type":"code","source":"#Commonly Used Libraries\nimport numpy as np # Linear algebra\nimport pandas as pd # Data processing, CSV file I/O (e.g. pd.read_csv)\nimport re #Regular expressions (Used for strings)\nfrom collections import Counter #Counts amount of occurrences\nimport seaborn as sns  # Machine learning; Statistical graphics & visualizations\nimport xgboost as xgb  # Machine learning; Gradient boosted decision trees \nfrom scipy import stats # Stats\n\n#Matplotlib\nfrom matplotlib import pyplot as plt #Visualizations\nimport plotly.offline as py #Composing, editing, and sharing interactive data visualization \nfrom matplotlib import pyplot\npy.init_notebook_mode(connected=True) #Enable plotly interactive plotting\nimport plotly.graph_objs as go #Graph Objetcs\nimport plotly.tools as tls #Tools\nfrom collections import Counter #Counts amount of occurrences\nimport xgboost as xgb  # Machine learning; Gradient boosted decision trees \nimport seaborn as sns  # Machine learning; Statistical graphics & visualizations\n\n#Machine Learning Algorithims\nimport sklearn #Machine Learning\nfrom sklearn.linear_model import LogisticRegression #Logistic Regression\nfrom sklearn.svm import SVC, LinearSVC #Support Vector Classifier\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier) #Several Classifiers\nfrom sklearn.neighbors import KNeighborsClassifier #KNeighbors\nfrom sklearn.naive_bayes import GaussianNB #Assumes Gaussian Distribution\nfrom sklearn.linear_model import Perceptron #Prediction Error\nfrom sklearn.linear_model import SGDClassifier #Stochastic Gradient Descent\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier #Decision Tree Classifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold #Statistical Approaches\nfrom sklearn.preprocessing import StandardScaler #Scales To Unit Variance\nfrom sklearn.model_selection import train_test_split #Train-Test Split\nfrom sklearn.metrics import accuracy_score,classification_report, precision_recall_curve, confusion_matrix #Statistical Approaches\nfrom scipy.stats import zscore\nfrom scipy.stats.mstats import winsorize\n\nfrom sklearn.exceptions import ConvergenceWarning \nConvergenceWarning('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:47:37.571635Z","iopub.execute_input":"2023-12-07T15:47:37.572171Z","iopub.status.idle":"2023-12-07T15:47:37.591749Z","shell.execute_reply.started":"2023-12-07T15:47:37.572137Z","shell.execute_reply":"2023-12-07T15:47:37.589820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read data\ntrain = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:47:44.030389Z","iopub.execute_input":"2023-12-07T15:47:44.030906Z","iopub.status.idle":"2023-12-07T15:47:44.075759Z","shell.execute_reply.started":"2023-12-07T15:47:44.030864Z","shell.execute_reply":"2023-12-07T15:47:44.073905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. **Data Exploration(EDA)**","metadata":{}},{"cell_type":"code","source":"#Distribution of numerical independent variables\nnumerical_columns = ['Age', 'Fare', 'Parch', 'SibSp']\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\nfig.suptitle(\"Distribution of Numerical Variables\", fontsize=16)\nfor i,column in enumerate(numerical_columns):\n    sns.histplot(train[column], bins = 20, kde = True, ax = axes[i//2,i%2])\n    sns.despine()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:47:48.032211Z","iopub.execute_input":"2023-12-07T15:47:48.032574Z","iopub.status.idle":"2023-12-07T15:47:49.122978Z","shell.execute_reply.started":"2023-12-07T15:47:48.032546Z","shell.execute_reply":"2023-12-07T15:47:49.121602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Engineering With Relevant Themes\n#Sex\ntrain['Sex'] = train['Sex'].map({'male': 0, 'female': 1})\ntrain['Embarked'] = train ['Embarked'].map({'S':0,'C':1,'Q':2})\n\n#Family\ntrain['Family'] = train['SibSp'] + train['Parch'] + 1\n\n#Make Age Categorical\nage_bins = [0,9,19,29,39,49,59,69,89]\nage_labels = ['0-9','10-19','20-29','30-39','40-49','50-59','60-69','70+']\ntrain['AgeCategory'] = pd.cut(train['Age'], bins = age_bins, labels = age_labels, right = False)\n\n#Make Fare Categorical\nfare_bins = [0,49,99,150]\nfare_labels = ['0-49','50-100','100+']\ntrain['FareCategory'] = pd.cut(train['Fare'], bins = fare_bins, labels = fare_labels, right = False)\n\n#Relevant variables\ncategorical_vars = ['Pclass', 'Sex', 'AgeCategory', 'FareCategory', 'Family', 'Embarked',]\n\n#Create a subplot with multiple categorical variables\nfig, axes = plt.subplots(nrows = 2, ncols = 3, figsize=(15, 10))\naxes = axes.flatten()\n\n# Iterate over each categorical variable and create a countplot\nfor i, var in enumerate(categorical_vars):\n    sns.countplot(x=var, hue='Survived', data=train, ax=axes[i])\n    axes[i].set_title(f'Survival Counts by {var}')\n    axes[i].set_xlabel(var)\n    axes[i].set_ylabel('Count')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:48.969583Z","iopub.execute_input":"2023-12-07T15:43:48.970140Z","iopub.status.idle":"2023-12-07T15:43:50.682473Z","shell.execute_reply.started":"2023-12-07T15:43:48.970075Z","shell.execute_reply":"2023-12-07T15:43:50.681109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show Survival Rates for different features\ncolumns_to_plot = ['FareCategory', 'AgeCategory', 'Family', 'Pclass', 'Sex', 'Embarked']\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\naxes = axes.flatten()\n\nfor i, column in enumerate(columns_to_plot):\n    sns.barplot(x=column, y='Survived', data=train, ax=axes[i])\n    axes[i].set_title(f'Survival Rate by {column}')\n    axes[i].set_xlabel(column)\n    axes[i].set_ylabel('Survival Rate')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:50.685061Z","iopub.execute_input":"2023-12-07T15:43:50.685425Z","iopub.status.idle":"2023-12-07T15:43:52.822981Z","shell.execute_reply.started":"2023-12-07T15:43:50.685394Z","shell.execute_reply":"2023-12-07T15:43:52.821826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. **Data Cleaning**","metadata":{}},{"cell_type":"code","source":"# Deal with Outliers\nnumerical_columns = ['Age', 'SibSp', 'Parch', 'Fare']\n\ndef remove_outliers_iqr(data, columns):\n    replaced_outliers_count = {}  # Initialize the dictionary to store the count of replaced outliers\n    \n    for column in columns: \n        Q1 = data[column].quantile(0.25)\n        Q3 = data[column].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        # Count the outliers before replacement\n        outliers_before = sum((data[column] < lower_bound) | (data[column] > upper_bound))\n        # Replace the outliers\n        data[column] = data.apply(lambda row: lower_bound if row[column] < lower_bound else (upper_bound if row[column] > upper_bound else row[column]), axis=1)\n        # Count the outliers after replacement\n        outliers_after = sum((data[column] < lower_bound) | (data[column] > upper_bound))\n        # Store the count of replaced outliers\n        replaced_outliers_count[column] = outliers_before - outliers_after\n    \n    return data, replaced_outliers_count\n\nreplace_outliers_train, replaced_outliers_count_train = remove_outliers_iqr(train.copy(), numerical_columns)\nreplace_outliers_test, replaced_outliers_count_test = remove_outliers_iqr(test.copy(), numerical_columns)\n\n# Print the counts of replaced outliers\nprint(\"Replaced Outliers in Train Data:\")\nprint(replaced_outliers_count_train)\n\nprint(\"\\nReplaced Outliers in Test Data:\")\nprint(replaced_outliers_count_test)\n\n# Ensure no data was accidentally deleted\nprint(\"\\nOriginal Train Shape:\", train.shape)\nprint(\"Train Shape After Outlier Replacement:\", replace_outliers_train.shape)\n\nprint(\"Original Test Shape:\", test.shape)\nprint(\"Test Shape After Outlier Replacement:\", replace_outliers_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:52.824181Z","iopub.execute_input":"2023-12-07T15:43:52.824498Z","iopub.status.idle":"2023-12-07T15:43:52.950721Z","shell.execute_reply.started":"2023-12-07T15:43:52.824471Z","shell.execute_reply":"2023-12-07T15:43:52.949780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replace null values for both sets\n#Train set\ntrain_age_median = train['Age'].median()\ntrain['Age'] = train['Age'].replace(np.nan, train_age_median)\n\ntrain_fare_median = train['Fare'].median()\ntrain['Fare'] = train['Fare'].replace(np.nan, train_fare_median)\n\n#Test set\ntest_age_median = test['Age'].median()\ntest['Age'] = test['Age'].replace(np.nan, test_age_median)\n\ntest_fare_median = test['Fare'].median()\ntest['Fare'] = test['Fare'].replace(np.nan, test_fare_median)\n\ntest.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:52.951854Z","iopub.execute_input":"2023-12-07T15:43:52.952445Z","iopub.status.idle":"2023-12-07T15:43:52.968423Z","shell.execute_reply.started":"2023-12-07T15:43:52.952412Z","shell.execute_reply":"2023-12-07T15:43:52.967086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Match Feature Engineering from training Data\n#Sex\ntest['Sex'] = test['Sex'].map({'male': 0, 'female': 1})\n\n#Family \ntest['Family'] = test['SibSp'] + test['Parch'] + 1\n\n#Make Age Categorical\nage_bins = [0,9,19,29,39,49,59,69,89]\nage_labels = ['0-9','10-19','20-29','30-39','40-49','50-59','60-69','70+']\ntest['AgeCategory'] = pd.cut(test['Age'], bins = age_bins, labels = age_labels, right = False)\n\n#Make Fare Categorical\nfare_bins = [0,49,99,150]\nfare_labels = ['0-49','50-100','100+']\ntest['FareCategory'] = pd.cut(test['Fare'], bins = fare_bins, labels = fare_labels, right = False)\n \ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:52.969621Z","iopub.execute_input":"2023-12-07T15:43:52.970314Z","iopub.status.idle":"2023-12-07T15:43:52.999044Z","shell.execute_reply.started":"2023-12-07T15:43:52.970243Z","shell.execute_reply":"2023-12-07T15:43:52.997693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replace null values for both new Columns\n#Train Set\ntrain_agecategory_mode = train['AgeCategory'].mode().iloc[0]\ntrain['AgeCategory'] = train['AgeCategory'].fillna(train_agecategory_mode)\n\ntrain_farecategory_mode = train['FareCategory'].mode().iloc[0]\ntrain['FareCategory'] = train['FareCategory'].fillna(train_farecategory_mode)\n\n#Test Set\ntest_agecategory_mode = test['AgeCategory'].mode().iloc[0]\ntest['AgeCategory'] = test['AgeCategory'].fillna(test_agecategory_mode)\n\ntest_farecategory_mode = test['FareCategory'].mode().iloc[0]\ntest['FareCategory'] = test['FareCategory'].fillna(test_farecategory_mode)\n\n#Display nulls\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:53.000443Z","iopub.execute_input":"2023-12-07T15:43:53.000832Z","iopub.status.idle":"2023-12-07T15:43:53.019112Z","shell.execute_reply.started":"2023-12-07T15:43:53.000791Z","shell.execute_reply":"2023-12-07T15:43:53.017180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop Unnecessary Columns from both sets of data\n#Train Set\ntrain_columns_to_drop = ['PassengerId','Name','Age','Fare','SibSp','Parch','Ticket','Cabin','Embarked']\ntrain = train.drop(columns = train_columns_to_drop)\n#Test Set\ntest_columns_to_drop = ['Name','Age','Fare','SibSp','Parch','Ticket','Cabin','Embarked']\ntest = test.drop(columns = test_columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:53.021541Z","iopub.execute_input":"2023-12-07T15:43:53.022139Z","iopub.status.idle":"2023-12-07T15:43:53.029670Z","shell.execute_reply.started":"2023-12-07T15:43:53.022106Z","shell.execute_reply":"2023-12-07T15:43:53.028421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert data types for both sets of data\n#Train Set\ntrain['AgeCategory'] = train['AgeCategory'].cat.codes.astype('Int64')\ntrain['FareCategory'] = train['FareCategory'].cat.codes.astype('Int64')\n#Test Set\ntest['AgeCategory'] = test['AgeCategory'].cat.codes.astype('Int64')\ntest['FareCategory'] = test['FareCategory'].cat.codes.astype('Int64')\n\nprint(train.dtypes)\nprint(test.dtypes)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:53.033139Z","iopub.execute_input":"2023-12-07T15:43:53.033588Z","iopub.status.idle":"2023-12-07T15:43:53.052030Z","shell.execute_reply.started":"2023-12-07T15:43:53.033554Z","shell.execute_reply":"2023-12-07T15:43:53.050424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#View Train Set\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:53.053448Z","iopub.execute_input":"2023-12-07T15:43:53.054048Z","iopub.status.idle":"2023-12-07T15:43:53.067723Z","shell.execute_reply.started":"2023-12-07T15:43:53.054013Z","shell.execute_reply":"2023-12-07T15:43:53.066754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#View Test Set\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:53.069667Z","iopub.execute_input":"2023-12-07T15:43:53.070147Z","iopub.status.idle":"2023-12-07T15:43:53.086634Z","shell.execute_reply.started":"2023-12-07T15:43:53.070105Z","shell.execute_reply":"2023-12-07T15:43:53.085675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. **Model Building**","metadata":{}},{"cell_type":"code","source":"#Pearson correlation to see relationships between variables\ncolormap = plt.cm.RdBu\nplt.figure(figsize = (14,12))\nplt.title('Pearson Correlation of Features', y = 1.05, size = 15)\nsns.heatmap(train.astype(float).corr(),linewidths = .1, vmax = 1.0, square = True, cmap = colormap, linecolor = 'white', annot = True)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:43:53.088065Z","iopub.execute_input":"2023-12-07T15:43:53.089160Z","iopub.status.idle":"2023-12-07T15:43:53.612624Z","shell.execute_reply.started":"2023-12-07T15:43:53.089104Z","shell.execute_reply":"2023-12-07T15:43:53.610661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run different classification models\n#Create survived column in test data\ntest['Survived'] = ''\n\ntrain_data = train.drop('Survived', axis=1)\ntest_data = test.drop(['Survived', 'PassengerId'], axis=1)  # Remove 'PassengerId' from test data\ntarget = train['Survived']\n\n#Use K-fold cross validation\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\nclassifiers =[\n    KNeighborsClassifier(n_neighbors=13),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=13),\n    GaussianNB(),\n    SVC(),\n    ExtraTreeClassifier(),\n    GradientBoostingClassifier(n_estimators=10, learning_rate=1, max_features=3, max_depth=3, random_state=10),\n    AdaBoostClassifier(),\n    ExtraTreesClassifier()\n    ]\n\n#Create \ndef model_fit():\n    scoring = 'accuracy'\n    for i in range(len(classifiers)):\n        score = cross_val_score(classifiers[i], train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n        print(\"Score of Model\", i, \":\", round(np.mean(score) * 100, 2))\nmodel_fit()\n\n#Select the best classifier for test data\nfinal_classifier = SVC()\nfinal_classifier.fit(train_data, target)\n\n# Predict test data\ntest_prediction = final_classifier.predict(test_data)\ntest['Survived'] = test_prediction","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:46:37.268085Z","iopub.execute_input":"2023-12-07T15:46:37.268507Z","iopub.status.idle":"2023-12-07T15:46:41.549218Z","shell.execute_reply.started":"2023-12-07T15:46:37.268473Z","shell.execute_reply":"2023-12-07T15:46:41.548075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create submission data frame\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': test_prediction})\n\n#Specify file path and save to csv\nfile_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(file_path, index=False)\nprint(\"Successful Submission\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T15:47:21.485422Z","iopub.execute_input":"2023-12-07T15:47:21.485818Z","iopub.status.idle":"2023-12-07T15:47:21.498145Z","shell.execute_reply.started":"2023-12-07T15:47:21.485786Z","shell.execute_reply":"2023-12-07T15:47:21.496380Z"},"trusted":true},"execution_count":null,"outputs":[]}]}